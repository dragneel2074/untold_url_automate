{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10537184,"sourceType":"datasetVersion","datasetId":6519674}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Usage\nfirst_chapter_url = \"https://69shuba.cx/txt/29622/20566574\"\nfinal_url = \"https://69shuba.cx/txt/29622/20568492\"  # needed\nnovel_title = \"Sword of Dawnbreaker\"\nnovel_slug = \"-\".join(novel_title.lower().replace(\":\",\"\").replace(\"!\",\"\").replace(\"?\",\"\").strip().split())\nprint(novel_slug)\nchapter_start=1 #default is 1 for Numbering Scrapped Chapter 1, 2 etc\nstart_chapter_number = 1 #for translation Chapter\nend_chapter_number = 500 #translates from start chapter number to end_capter_number\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T09:33:01.779615Z","iopub.execute_input":"2025-01-21T09:33:01.77993Z","iopub.status.idle":"2025-01-21T09:33:01.786465Z","shell.execute_reply.started":"2025-01-21T09:33:01.779899Z","shell.execute_reply":"2025-01-21T09:33:01.785352Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Making changes in the prompt #changed 69shu to 69yuedu #changes to category_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T06:50:16.336124Z","iopub.execute_input":"2025-01-09T06:50:16.336536Z","iopub.status.idle":"2025-01-09T06:50:16.341575Z","shell.execute_reply.started":"2025-01-09T06:50:16.336492Z","shell.execute_reply":"2025-01-09T06:50:16.340322Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !pip install -U crawl4ai\n# !playwright install\n\n\n# !pip install -q playwright\n# !pip install nest_asyncio\n\n# !playwright install\n# !playwright install-deps    \n!pip install -q groq\n!pip install fake-useragent","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T09:33:01.788778Z","iopub.execute_input":"2025-01-21T09:33:01.789099Z","iopub.status.idle":"2025-01-21T09:34:44.734635Z","shell.execute_reply.started":"2025-01-21T09:33:01.789069Z","shell.execute_reply":"2025-01-21T09:34:44.733509Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import asyncio\n# from playwright.async_api import async_playwright, TimeoutError\nimport json\n# import nest_asyncio\nimport requests\nimport os\nimport random\nimport time\nfrom fake_useragent import UserAgent\nfrom groq import Groq\nfrom tenacity import retry, stop_after_attempt, wait_exponential\nfrom urllib.parse import urlparse, urljoin\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T09:34:44.736356Z","iopub.execute_input":"2025-01-21T09:34:44.736826Z","iopub.status.idle":"2025-01-21T09:34:45.546467Z","shell.execute_reply.started":"2025-01-21T09:34:44.736775Z","shell.execute_reply":"2025-01-21T09:34:45.545439Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"groq_74_api_key\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T09:34:45.547522Z","iopub.execute_input":"2025-01-21T09:34:45.547932Z","iopub.status.idle":"2025-01-21T09:34:45.675039Z","shell.execute_reply.started":"2025-01-21T09:34:45.547902Z","shell.execute_reply":"2025-01-21T09:34:45.673961Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Constants\nCHAPTERS_FILE = '/kaggle/input/picking-up-flowers/output.json'\n# CHAPTERS_FILE='/kaggle/working/scraped_chapters.json'\n# SPLIT_CHAPTERS_FILE='/kaggle/working/split_scraped_chapters.json'\nSPLIT_CHAPTERS_FILE='/kaggle/input/picking-up-flowers/split_scraped_chapters.json'\n\nTRANSLATIONS_FILE = '/kaggle/working/chapter_translated.json'\n# TRANSLATIONS_FILE = '/kaggle/input/ming-historical-grand-tutor/ming_chapter_translated.json'\n# GLOSSARY_FILE = '/kaggle/working/chapter_glossary.json'\nGLOSSARY_FILE='/kaggle/input/picking-up-flowers/chapter_glossarydfd.json'\n\nWP_URL = 'https://novelroutes.com/wp-json/wp/v2/posts'\nWP_USER = 'your_wordpress_username'  # Replace with your WordPress username\nWP_PASSWORD = 'your_wordpress_password'  # Replace with your WordPress password\n#WP_IMAGE_ID = 'your_featured_image_id'  # Replace with your featured image ID\napi_key = \"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\" #76\napi_key1 = \"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\" #078\napi_key2 = \"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\" #69\napi_key3 = \"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\" #77\napi_key4 = secret_value_0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T09:36:22.051303Z","iopub.execute_input":"2025-01-21T09:36:22.052085Z","iopub.status.idle":"2025-01-21T09:36:22.057827Z","shell.execute_reply.started":"2025-01-21T09:36:22.052046Z","shell.execute_reply":"2025-01-21T09:36:22.056789Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ua = UserAgent()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T09:34:45.684914Z","iopub.execute_input":"2025-01-21T09:34:45.685223Z","iopub.status.idle":"2025-01-21T09:34:45.783895Z","shell.execute_reply.started":"2025-01-21T09:34:45.685194Z","shell.execute_reply":"2025-01-21T09:34:45.782917Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\nasync def fetch_page(page, url):\n    await page.goto(url)\n    await page.wait_for_load_state('networkidle')\n    return page\n\nasync def scrape_uu(first_chapter_url, final_url=None):\n    async with async_playwright() as p:\n        browser = await p.chromium.launch()\n        context = await browser.new_context(user_agent=ua.random)\n        page = await context.new_page()\n\n        try:\n            # Navigate to the first chapter\n            page = await fetch_page(page, first_chapter_url)\n\n            chapters = []\n            next_url = first_chapter_url\n            chapter_count = 0\n\n            while next_url and (not final_url or next_url != final_url):\n                try:\n                    # Change user agent every 5 chapters\n                    if chapter_count % 5 == 0:\n                        await context.set_extra_http_headers({\"User-Agent\": ua.random})\n\n                    page = await fetch_page(page, next_url)\n                    await page.wait_for_selector('h1.pt10', state='visible', timeout=60000)\n\n                    chapter_data = await page.evaluate('''\n                        () => {\n                            const title = document.querySelector('h1.pt10')?.textContent.trim();\n                            const content = document.querySelector('p.readcotent.bbb.font-normal')?.textContent.trim();\n                            const nextUrl = document.querySelector('#linkNext')?.href;\n                            return { title, content, nextUrl };\n                        }\n                    ''')\n\n                    if chapter_data['title'] and chapter_data['content']:\n                        chapters.append({\n                            'title': chapter_data['title'],\n                            'content': chapter_data['content'],\n                            'url': next_url\n                        })\n\n                    print(f\"Scraped chapter {chapter_count + 1}: {chapter_data['title']}\")\n                    next_url = chapter_data['nextUrl']\n                    chapter_count += 1\n\n                    # Add a random delay between requests\n                    await asyncio.sleep(random.uniform(2, 5))\n\n                except Exception as e:\n                    print(f\"Error scraping chapter at {next_url}: {str(e)}\")\n                    await asyncio.sleep(60)  # Wait for 1 minute before trying the next chapter\n                    next_url = await page.evaluate('document.querySelector(\"#linkNext\")?.href')\n\n            await browser.close()\n            return chapters\n\n        except Exception as e:\n            print(f\"An error occurred during scraping: {str(e)}\")\n            await browser.close()\n            return None\n\nasync def scrape_ddxs(first_chapter_url, final_url=None):\n    async with async_playwright() as p:\n        browser = await p.chromium.launch()\n        context = await browser.new_context(user_agent=ua.random)\n        page = await context.new_page()\n\n        try:\n            # Navigate to the first chapter\n            page = await fetch_page(page, first_chapter_url)\n\n            chapters = []\n            next_url = first_chapter_url\n            chapter_count = 0\n\n            while next_url and (not final_url or next_url != final_url):\n                try:\n                    # Change user agent every 5 chapters\n                    if chapter_count % 5 == 0:\n                        await context.set_extra_http_headers({\"User-Agent\": ua.random})\n\n                    page = await fetch_page(page, next_url)\n                    await page.wait_for_selector('h1, .nr_title', state='visible', timeout=60000)\n\n                    chapter_data = await page.evaluate('''\n                        () => {\n                            const title = document.querySelector('h1')?.textContent.trim() || \n                                          document.querySelector('.nr_title')?.textContent.trim();\n                            const content = document.querySelector('#contents')?.textContent.trim() || \n                                            document.querySelector('#nr1')?.textContent.trim();\n                            const nextUrl = document.querySelector('#footlink a:nth-child(3)')?.href || \n                                            document.querySelector('#pb_next')?.href;\n                            return { title, content, nextUrl };\n                        }\n                    ''')\n\n                    if chapter_data['title'] and chapter_data['content']:\n                        # Remove the device message if present\n                        content = chapter_data['content']\n                        device_message_start = content.find('[Inform book lovers')\n                        if device_message_start != -1:\n                            device_message_end = content.find(']', device_message_start)\n                            if device_message_end != -1:\n                                content = content[:device_message_start] + content[device_message_end + 1:]\n                        \n                        chapters.append({\n                            'title': chapter_data['title'],\n                            'content': content.strip(),\n                            'url': next_url\n                        })\n\n                    print(f\"Scraped chapter {chapter_count + 1}: {chapter_data['title']}\")\n                    next_url = urljoin(next_url, chapter_data['nextUrl']) if chapter_data['nextUrl'] else None\n                    chapter_count += 1\n\n                    # Add a random delay between requests\n                    await asyncio.sleep(random.uniform(2, 5))\n\n                except Exception as e:\n                    print(f\"Error scraping chapter at {next_url}: {str(e)}\")\n                    await asyncio.sleep(60)  # Wait for 1 minute before trying the next chapter\n                    next_url = await page.evaluate('''\n                        () => document.querySelector('#footlink a:nth-child(3)')?.href || \n                              document.querySelector('#pb_next')?.href\n                    ''')\n                    next_url = urljoin(next_url, next_url) if next_url else None\n\n            await browser.close()\n            return chapters\n\n        except Exception as e:\n            print(f\"An error occurred during scraping: {str(e)}\")\n            await browser.close()\n            return None\n        \nasync def scrape_69shu(first_chapter_url, final_url=None):\n    async with async_playwright() as p:\n        browser = await p.chromium.launch()\n        context = await browser.new_context(user_agent=ua.random)\n        page = await context.new_page()\n\n        try:\n            # Navigate to the first chapter\n            page = await fetch_page(page, first_chapter_url)\n\n            chapters = []\n            next_url = first_chapter_url\n            chapter_count = 0\n\n            while next_url and (not final_url or next_url != final_url):\n                try:\n                    # Change user agent every 5 chapters\n                    if chapter_count % 5 == 0:\n                        await context.set_extra_http_headers({\"User-Agent\": ua.random})\n\n                    page = await fetch_page(page, next_url)\n                    await page.wait_for_selector('.txtnav', state='visible', timeout=60000)\n\n                    # Extract title\n                    title_element = await page.query_selector('.txtnav h1')\n                    title = await title_element.inner_text() if title_element else None\n\n                    if not title:\n                        title_element = await page.query_selector('.txtnav')\n                        if title_element:\n                            title_text = await title_element.inner_text()\n                            title = title_text.split('\\n')[0].strip()\n\n                    # Extract content\n                    content_element = await page.query_selector('.txtnav')\n                    content = await content_element.inner_text() if content_element else None\n\n                    # Extract next URL\n                    next_link = await page.query_selector('.page1 a:nth-child(4)')\n                    next_url = await next_link.get_attribute('href') if next_link else None\n\n                    if title and content:\n                        # Clean up the content\n                        content_lines = content.split('\\n')\n                        clean_content = '\\n'.join(line.strip() for line in content_lines if line.strip() and not line.strip().startswith('Chapter'))\n                        \n                        chapters.append({\n                            'title': title,\n                            'content': clean_content,\n                            'url': next_url\n                        })\n\n                    print(f\"Scraped chapter {chapter_count + 1}: {title}\")\n                    chapter_count += 1\n\n                    # Add a random delay between requests\n                    await asyncio.sleep(random.uniform(2, 5))\n\n                except Exception as e:\n                    print(f\"Error scraping chapter at {next_url}: {str(e)}\")\n                    await asyncio.sleep(60)  # Wait for 1 minute before trying the next chapter\n\n            await browser.close()\n            return chapters\n\n        except Exception as e:\n            print(f\"An error occurred during scraping: {str(e)}\")\n            await browser.close()\n            return None\n\nasync def scrape_xbanxia(first_chapter_url, final_url=None):\n    async with async_playwright() as p:\n        browser = await p.chromium.launch()\n        context = await browser.new_context(user_agent=ua.random)\n        page = await context.new_page()\n        try:\n            page = await fetch_page(page, first_chapter_url)\n            chapters = []\n            next_url = first_chapter_url\n            chapter_count = 0\n\n            while next_url and (not final_url or next_url != final_url):\n                try:\n                    if chapter_count % 5 == 0:\n                        await context.set_extra_http_headers({\"User-Agent\": ua.random})\n                    \n                    page = await fetch_page(page, next_url)\n                    \n                    # Wait for content to load\n                    await page.wait_for_selector('#nr_title', state='visible', timeout=60000)\n                    await page.wait_for_selector('#nr1', state='visible', timeout=60000)\n                    \n                    # Extract title\n                    title_element = await page.query_selector('#nr_title')\n                    title = await title_element.inner_text() if title_element else None\n                    \n                    # Extract content\n                    content_element = await page.query_selector('#nr1')\n                    content = await content_element.inner_text() if content_element else None\n                    \n                    # Extract next URL\n                    next_link = await page.query_selector('.nav2 .next a')\n                    next_url = await next_link.get_attribute('href') if next_link else None\n                    \n                    if next_url and not next_url.startswith('http'):\n                        base_url = '/'.join(first_chapter_url.split('/')[:3])\n                        next_url = base_url + next_url\n                    \n                    if title and content:\n                        # Clean up the content\n                        content_lines = content.split('\\n')\n                        clean_content = '\\n'.join(line.strip() for line in content_lines \n                                                if line.strip() and not line.strip().startswith('第'))\n                        \n                        chapters.append({\n                            'title': title.strip(),\n                            'content': clean_content,\n                            'url': next_url\n                        })\n                        \n                    print(f\"Scraped chapter {chapter_count + 1}: {title}\")\n                    chapter_count += 1\n                    \n                    # Random delay between requests\n                    await asyncio.sleep(random.uniform(2, 5))\n                    \n                except Exception as e:\n                    print(f\"Error scraping chapter at {next_url}: {str(e)}\")\n                    await asyncio.sleep(60)  # Wait for 1 minute before retrying\n                    \n            await browser.close()\n            return chapters\n            \n        except Exception as e:\n            print(f\"An error occurred during scraping: {str(e)}\")\n            await browser.close()\n            return None\n        \n\nasync def scrape_22shuqu(first_chapter_url, final_url=None):\n    async with async_playwright() as p:\n        browser = await p.chromium.launch()\n        context = await browser.new_context(user_agent=ua.random)\n        page = await context.new_page()\n        try:\n            # Navigate to the first chapter\n            page = await fetch_page(page, first_chapter_url)\n            chapters = []\n            next_url = first_chapter_url\n            chapter_count = 0\n            while next_url and (not final_url or next_url != final_url):\n                try:\n                    # Change user agent every 5 chapters\n                    if chapter_count % 5 == 0:\n                        await context.set_extra_http_headers({\"User-Agent\": ua.random})\n                    page = await fetch_page(page, next_url)\n                    await page.wait_for_selector('h1.title', state='visible', timeout=60000)\n                    chapter_data = await page.evaluate('''\n                        () => {\n                            const title = document.querySelector('h1.title')?.textContent.trim();\n                            const content = document.querySelector('div.content')?.textContent.trim();\n                            const nextUrl = document.querySelector('#next_url')?.href;\n                            return { title, content, nextUrl };\n                        }\n                    ''')\n                    if chapter_data['title'] and chapter_data['content']:\n                        chapters.append({\n                            'title': chapter_data['title'],\n                            'content': chapter_data['content'],\n                            'url': next_url\n                        })\n                    print(f\"Scraped chapter {chapter_count + 1}: {chapter_data['title']}\")\n                    next_url = chapter_data['nextUrl']\n                    chapter_count += 1\n                    # Add a random delay between requests\n                    await asyncio.sleep(random.uniform(2, 5))\n                except Exception as e:\n                    print(f\"Error scraping chapter at {next_url}: {str(e)}\")\n                    await asyncio.sleep(60)  # Wait for 1 minute before trying the next chapter\n                    next_url = await page.evaluate('document.querySelector(\"#next_url\")?.href')\n            await browser.close()\n            return chapters\n        except Exception as e:\n            print(f\"An error occurred during scraping: {str(e)}\")\n            await browser.close()\n            return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T06:52:00.577946Z","iopub.execute_input":"2025-01-09T06:52:00.578332Z","iopub.status.idle":"2025-01-09T06:52:00.614556Z","shell.execute_reply.started":"2025-01-09T06:52:00.578301Z","shell.execute_reply":"2025-01-09T06:52:00.613523Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"async def scrape_task(first_chapter_url, final_url=None):\n    \"\"\"Scrape chapters and save to JSON file.\"\"\"\n    domain = urlparse(first_chapter_url).netloc\n    if 'uukanshu' in domain:\n        result = await scrape_uu(first_chapter_url, final_url)\n    elif 'ddxs' in domain:\n        result = await scrape_ddxs(first_chapter_url, final_url)\n    elif '69shu' in domain:\n        result = await scrape_69shu(first_chapter_url, final_url)\n    elif 'xbanxia' in domain:\n        result = await scrape_xbanxia(first_chapter_url,final_url)\n    else:\n        print(f\"Unsupported domain: {domain}\")\n        return\n    if result:\n        with open(CHAPTERS_FILE, 'w', encoding='utf-8') as f:\n            json.dump(result, f, ensure_ascii=False, indent=2)\n        print(f'Scraping completed. Data saved to {CHAPTERS_FILE}')\n    else:\n        print('Scraping failed or was interrupted.')\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T06:52:00.616065Z","iopub.execute_input":"2025-01-09T06:52:00.616885Z","iopub.status.idle":"2025-01-09T06:52:00.630559Z","shell.execute_reply.started":"2025-01-09T06:52:00.616838Z","shell.execute_reply":"2025-01-09T06:52:00.629542Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"async def main_scrape(first_chapter_url, final_url=None):\n    await scrape_task(first_chapter_url, final_url)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T06:52:00.631735Z","iopub.execute_input":"2025-01-09T06:52:00.632074Z","iopub.status.idle":"2025-01-09T06:52:00.646064Z","shell.execute_reply.started":"2025-01-09T06:52:00.632045Z","shell.execute_reply":"2025-01-09T06:52:00.645188Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# await main_scrape(first_chapter_url, final_url)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T06:52:00.647376Z","iopub.execute_input":"2025-01-09T06:52:00.647942Z","iopub.status.idle":"2025-01-09T07:02:46.865317Z","shell.execute_reply.started":"2025-01-09T06:52:00.647888Z","shell.execute_reply":"2025-01-09T07:02:46.864247Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cat name is Lady Calico.\n# Main Character name is Song You\n# Other keyword to pay attention is Mountain God, Hidden Dragon Temple, fire element spell, Five Elements Method,\n# Four Seasons Rotation Method, mortal realm, divine abilities, Jingzhe, celestial might, Heavenly Dao,Heavenly Palace,\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T07:02:46.866581Z","iopub.execute_input":"2025-01-09T07:02:46.866881Z","iopub.status.idle":"2025-01-09T07:02:46.871334Z","shell.execute_reply.started":"2025-01-09T07:02:46.866852Z","shell.execute_reply":"2025-01-09T07:02:46.870227Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import json\n\n# def split_long_chapter(title, content, max_length=2000):\n#     \"\"\"\n#     Split a long chapter into multiple parts while preserving paragraph and sentence integrity.\n#     Splits occur at newline (\\n) or sentence-ending symbol (。).\n#     \"\"\"\n#     print(f\"Processing chapter: {title}\")\n#     chinese_char_count = sum(1 for char in content if '\\u4e00' <= char <= '\\u9fff')\n#     print(f\"Total Chinese characters in chapter: {chinese_char_count}\")\n\n#     if chinese_char_count <= max_length:\n#         print(f\"Chapter '{title}' does not exceed the max length ({max_length}). No splitting needed.\")\n#         return [{\"title\": title, \"content\": content}]\n    \n#     print(f\"Chapter '{title}' exceeds the max length ({max_length}). Splitting into parts...\")\n#     parts = []\n#     current_part = []\n#     current_length = 0\n#     part_number = 1\n\n#     # Split by sentence-ending symbol or newline\n#     segments = content.split(\"。\")\n#     for segment in segments:\n#         segment = segment.strip()\n#         if not segment:\n#             continue\n\n#         segment_length = len(segment) + 1  # Add 1 for the \"。\" symbol\n#         if current_length + segment_length > max_length and current_part:\n#             print(f\"Part {part_number} created with length {current_length}. Moving to next part...\")\n#             # Save current part\n#             parts.append({\n#                 \"title\": f\"{title} Part {part_number}\",\n#                 \"content\": \"。\".join(current_part) + \"。\"  # Add back \"。\"\n#             })\n#             current_part = [segment]\n#             current_length = segment_length\n#             part_number += 1\n#         else:\n#             current_part.append(segment)\n#             current_length += segment_length\n\n#     # Save the last part\n#     if current_part:\n#         print(f\"Final part {part_number} created with length {current_length}.\")\n#         parts.append({\n#             \"title\": f\"{title} Part {part_number}\",\n#             \"content\": \"。\".join(current_part) + \"。\"\n#         })\n\n#     print(f\"Chapter '{title}' split into {len(parts)} parts.\")\n#     return parts\n\n\n# def process_chapters(input_file, output_file, max_length=5000):\n#     \"\"\"\n#     Process chapters from an input JSON file, splitting long chapters if necessary,\n#     and save the result to an output JSON file.\n#     \"\"\"\n#     print(f\"Loading chapters from: {input_file}\")\n#     with open(input_file, 'r', encoding='utf-8') as f:\n#         chapters = json.load(f)\n\n#     print(f\"Total chapters to process: {len(chapters)}\")\n#     processed_chapters = []\n#     for idx, chapter in enumerate(chapters, start=1):\n#         title = chapter['title']\n#         content = chapter['content']\n#         print(f\"\\nProcessing chapter {idx}/{len(chapters)}: {title}\")\n#         print(f\"Original content length: {len(content)}\")\n#         split_chapters = split_long_chapter(title, content, max_length)\n#         processed_chapters.extend(split_chapters)\n\n#     print(f\"\\nSaving processed chapters to: {output_file}\")\n#     with open(output_file, 'w', encoding='utf-8') as f:\n#         json.dump(processed_chapters, f, ensure_ascii=False, indent=2)\n\n#     print(f\"Processed chapters saved successfully. Total chapters/parts: {len(processed_chapters)}\")\n\n\n# # Example usage:\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\ndef split_long_chapter(title, content, max_length=2000):\n    \"\"\"\n    Split a long chapter into multiple parts while preserving paragraph and sentence integrity.\n    Splits occur at newline (\\n) or sentence-ending symbol (。).\n    \"\"\"\n    # Count only Chinese characters for length check\n    chinese_char_count = sum(1 for char in content if '\\u4e00' <= char <= '\\u9fff')\n    \n    if chinese_char_count <= max_length:\n        return [{\"title\": title, \"content\": content}]\n    \n    parts = []\n    current_part = []\n    current_chinese_count = 0\n    part_number = 1\n    \n    # First split by paragraphs (newlines)\n    paragraphs = content.split('\\n')\n    \n    for paragraph in paragraphs:\n        if not paragraph.strip():\n            continue\n            \n        # Split paragraph into sentences\n        sentences = paragraph.split('。')\n        sentences = [s.strip() + '。' for s in sentences if s.strip()]\n        \n        for sentence in sentences:\n            sentence_chinese_count = sum(1 for char in sentence if '\\u4e00' <= char <= '\\u9fff')\n            \n            # If adding this sentence would exceed the limit\n            if current_chinese_count + sentence_chinese_count > max_length and current_part:\n                # Save current part\n                part_content = '\\n'.join(current_part)\n                parts.append({\n                    \"title\": f\"{title} Part {part_number}\",\n                    \"content\": part_content\n                })\n                # Start new part\n                current_part = [sentence]\n                current_chinese_count = sentence_chinese_count\n                part_number += 1\n            else:\n                current_part.append(sentence)\n                current_chinese_count += sentence_chinese_count\n    \n    # Save the last part if there's anything remaining\n    if current_part:\n        part_content = '\\n'.join(current_part)\n        parts.append({\n            \"title\": f\"{title} Part {part_number}\",\n            \"content\": part_content\n        })\n    \n    return parts\n\ndef process_chapters(input_file, output_file, max_length=5000):\n    \"\"\"\n    Process chapters from an input JSON file, splitting long chapters if necessary,\n    and save the result to an output JSON file.\n    \"\"\"\n    try:\n        with open(input_file, 'r', encoding='utf-8') as f:\n            chapters = json.load(f)\n            \n        processed_chapters = []\n        for chapter in chapters:\n            title = chapter['title']\n            content = chapter['content']\n            \n            split_chapters = split_long_chapter(title, content, max_length)\n            processed_chapters.extend(split_chapters)\n            \n        with open(output_file, 'w', encoding='utf-8') as f:\n            json.dump(processed_chapters, f, ensure_ascii=False, indent=2)\n            \n        return len(processed_chapters)\n    except Exception as e:\n        print(f\"Error processing chapters: {str(e)}\")\n        raise\n\n# # Example usage:\n# if __name__ == \"__main__\":\n#     input_file = \"chapters.json\"\n#     output_file = \"processed_chapters.json\"\n#     total_chapters = process_chapters(input_file, output_file, max_length=5000)\n#     print(f\"Successfully processed {total_chapters} chapters/parts\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T09:36:39.666332Z","iopub.execute_input":"2025-01-21T09:36:39.666726Z","iopub.status.idle":"2025-01-21T09:36:39.679547Z","shell.execute_reply.started":"2025-01-21T09:36:39.666692Z","shell.execute_reply":"2025-01-21T09:36:39.678687Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CHAPTERS_FILE = '/kaggle/input/mahaya/scraped_chapters.json'\n# SPLIT_CHAPTERS_FILE = '/kaggle/working/split_chapters.json'\n# process_chapters(CHAPTERS_FILE,SPLIT_CHAPTERS_FILE )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T09:36:43.652556Z","iopub.execute_input":"2025-01-21T09:36:43.652937Z","iopub.status.idle":"2025-01-21T09:36:44.362994Z","shell.execute_reply.started":"2025-01-21T09:36:43.652904Z","shell.execute_reply":"2025-01-21T09:36:44.361884Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\nimport json\nimport time\n\ndef create_glossary():\n    \"\"\"Create a glossary from random chapters and refine it using Groq API.\"\"\"\n    with open(SPLIT_CHAPTERS_FILE, 'r', encoding='utf-8') as f:\n        book_data = json.load(f)  # book_data is a list of chapters\n    \n    # Select 20 random chapters from the first 100 chapters\n    random_chapters = random.sample(book_data, min(20, len(book_data)))\n    \n    api_keys = [api_key4]\n    current_key_index = 0\n    preliminary_glossary = []\n    \n    for i, chapter in enumerate(random_chapters):\n        if i % 5 == 0 and i != 0:\n            current_key_index = (current_key_index + 1) % len(api_keys)\n        \n        current_api_key = api_keys[current_key_index]\n        client = Groq(api_key=current_api_key)\n        \n        max_retries = 3\n        retry_count = 0\n        while retry_count < max_retries:\n            try:\n                prompt = f\"\"\"Analyze the following Chinese web novel chapter and create a glossary of 5 important terms or names. Each entry should include the Chinese term and its English equivalent or explanation. Translate character names, locations names, unique concepts, cultivation levels, power levels, power techniques, or culturally specific terms to English.\nThe target audience are people from USA that don't know much about Chinese language and culture.\nVery important Note: Only Use Pinyin for Character's Name. \n\nChinese chapter:\n{chapter['content']}\n\n\nCreate a glossary of 5 terms in the following format:\nChinese Term: English Equivalent\nfor example: 朱士久 : Zhu Shijiu\n\n\"\"\"\n\n                chat_completion = client.chat.completions.create(\n                    messages=[{\"role\": \"user\", \"content\": prompt}],\n                    model=\"llama3-70b-8192\",\n                    timeout=30\n                )\n                chapter_glossary = chat_completion.choices[0].message.content\n                preliminary_glossary.extend(chapter_glossary.split('\\n'))\n                print(f\"Created glossary entries for chapter: {chapter['title']}\")\n                break\n            except Exception as e:\n                retry_count += 1\n                if retry_count < max_retries:\n                    print(f\"Error processing chapter {chapter['title']}: {str(e)}\")\n                    print(f\"Retrying in 60 seconds... (Attempt {retry_count + 1} of {max_retries})\")\n                    time.sleep(60)\n                else:\n                    print(f\"Failed to process chapter {chapter['title']} after {max_retries} attempts: {str(e)}\")\n        \n        time.sleep(5)\n    \n    # Refine the glossary\n    current_api_key = api_keys[0]  # Use the first API key for refinement\n    client = Groq(api_key=current_api_key)\n    \n    refine_prompt = \"\"\"Refine the following glossary for a Chinese web novel. Remove duplicates, redundant entries, and irrelevant words. Ensure consistency in naming and explanations.\nProvide the output in JSON Format.\nPreliminary Glossary:\n{}\n\nRetain people's names in Pinyin format (e.g., Chen Jingle), but fully translate all other terms, phrases, and concepts into English. Avoid using Pinyin for non-name elements to ensure clarity and natural flow for English readers.\nProvide the refined glossary in the following format:\nChinese Characters: English Equivalent (No Explanations)\nfor example: 朱士久 : Zhu Shijiu\n白家 : Bai Family\n成长系统: Growth System ( not \"Chengzhang Xitong)\n\"\"\".format('\\n'.join(preliminary_glossary))\n\n    chat_completion = client.chat.completions.create(\n        messages=[{\"role\": \"user\", \"content\": refine_prompt}],\n        model=\"llama3-70b-8192\",\n        timeout=60\n    )\n    refined_glossary = chat_completion.choices[0].message.content\n    \n    # Save the refined glossary\n    with open(GLOSSARY_FILE, 'w', encoding='utf-8') as f:\n        json.dump(refined_glossary.split('\\n'), f, ensure_ascii=False, indent=2)\n    print(f'Glossary creation completed. Glossary saved to {GLOSSARY_FILE}')\n    # Read and print the glossary\n    with open(GLOSSARY_FILE, 'r', encoding='utf-8') as f:\n        glossary = json.load(f)\n        print(\"\\nGlossary Contents:\")\n        for term in glossary:\n            print(term)\n# Usage\n# create_glossary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T09:37:24.01009Z","iopub.execute_input":"2025-01-21T09:37:24.010972Z","iopub.status.idle":"2025-01-21T09:37:24.023519Z","shell.execute_reply.started":"2025-01-21T09:37:24.010937Z","shell.execute_reply":"2025-01-21T09:37:24.022383Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# create_glossary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T09:37:30.557491Z","iopub.execute_input":"2025-01-21T09:37:30.557893Z","iopub.status.idle":"2025-01-21T09:47:17.849605Z","shell.execute_reply.started":"2025-01-21T09:37:30.557859Z","shell.execute_reply":"2025-01-21T09:47:17.848597Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Gemini + Groq","metadata":{}},{"cell_type":"code","source":"# import json\n# import time\n# import random\n# from groq import Groq\n# import google.generativeai as genai\n# from kaggle_secrets import UserSecretsClient\n# user_secrets = UserSecretsClient()\n\n\n# def translate_task(start_chapter=1, end_chapter=None):\n#     \"\"\"Translate Chinese chapters to English using Gemini API, falling back to Groq API if needed, and save to JSON file.\"\"\"\n#     with open(CHAPTERS_FILE, 'r', encoding='utf-8') as f:\n#         book_data = json.load(f)\n#     with open(GLOSSARY_FILE, 'r', encoding='utf-8') as f:\n#         glossary = json.load(f)\n#     formatted_glossary = \"\\n\".join(glossary)\n    \n#     groq_api_keys = [api_key4]\n#     current_key_index = 0\n#     translations = []\n    \n#     # Configure Gemini\n#     genai.configure(api_key=user_secrets.get_secret(\"google_api_key\"))\n#     gemini_model = genai.GenerativeModel(\n#         model_name=\"gemini-1.5-flash\",\n#         generation_config={\n#             \"temperature\": 1,\n#             \"top_p\": 0.95,\n#             \"top_k\": 64,\n#             \"max_output_tokens\": 8192,\n#         }\n#     )\n#     if end_chapter != None:\n#         chapters_to_translate = book_data[start_chapter-1:end_chapter]\n#     else:\n#         chapters_to_translate= book_data\n    \n#     for i, chapter in enumerate(chapters_to_translate):\n#         if i % 10 == 0 and i != 0:\n#             current_key_index = (current_key_index + 1) % len(groq_api_keys)\n        \n#         prompt = f\"\"\"Translate the following Chinese web novel chapter to English. Maintain the original tone and style of the novel. Preserve any cultural references or idioms, providing brief explanations in parentheses if necessary. Ensure the translation flows naturally in English while staying true to the original text.\n# If Paragraphs are stuck together, split them. Retain people's names in Pinyin format (e.g., Chen Jingle), but fully translate all other terms, phrases, and concepts into English. Avoid using Pinyin for non-name elements to ensure clarity and natural flow for English readers.\n# Glossary:\n# {formatted_glossary}\n\n# Chinese chapter:\n# {chapter['content']}\n# Note: No introductory sentences nor concluding sentences. Just directly provide the translation.\n# Translate the above text to English, using the glossary for consistent translations of key terms:\"\"\"\n        \n#         # Try Gemini first\n#         for attempt in range(2):\n#             try:\n#                 gemini_response = gemini_model.generate_content(prompt)\n#                 translation = gemini_response.text\n#                 break\n#             except Exception as e:\n#                 print(f\"Gemini error (attempt {attempt + 1}): {str(e)}\")\n#                 if attempt == 1:  # If this was the second attempt, move to Groq\n#                     print(\"Falling back to Groq LLaMA model\")\n#                     translation = None\n#                 else:\n#                     time.sleep(60)  # Wait before retrying Gemini\n        \n#         # If Gemini failed, try Groq\n#         if translation is None:\n#             current_api_key = groq_api_keys[current_key_index]\n#             client = Groq(api_key=current_api_key)\n#             for attempt in range(2):\n#                 try:\n#                     chat_completion = client.chat.completions.create(\n#                         messages=[{\"role\": \"user\", \"content\": prompt}],\n#                         model=\"llama3-70b-8192\",\n#                         timeout=30\n#                     )\n#                     translation = chat_completion.choices[0].message.content\n#                     break\n#                 except Exception as e:\n#                     print(f\"Groq error (attempt {attempt + 1}): {str(e)}\")\n#                     if attempt == 1:  # If this was the second Groq attempt\n#                         print(f\"Failed to translate Chapter {start_chapter + i} after all attempts\")\n#                         translation = f\"TRANSLATION FAILED: {chapter['title']}\"\n#                     else:\n#                         time.sleep(60)  # Wait before retrying Groq\n        \n#         translations.append({\n#             'title': chapter['title'],\n#             'translated_content': translation\n#         })\n#         print(f\"Translated: {chapter['title']} (Chapter {start_chapter + i})\")\n#         print(translation[:500] + \"...\")  # Print first 500 characters\n#         print('=======================================')\n        \n#         time.sleep(5)  # Sleep between requests\n    \n#     with open(TRANSLATIONS_FILE, 'w', encoding='utf-8') as f:\n#         json.dump(translations, f, ensure_ascii=False, indent=2)\n#     print(f'Translation completed. Translations saved to {TRANSLATIONS_FILE}')\n\n# # Usage\n# # translate_task(start_chapter=1, end_chapter=100)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-09T07:49:36.588Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"openai from pollinations + gemini + groq","metadata":{}},{"cell_type":"code","source":"# import json\n# import time\n# import random\n# import requests\n# from groq import Groq\n# import google.generativeai as genai\n# from kaggle_secrets import UserSecretsClient\n\n# user_secrets = UserSecretsClient()\n\n# def translate_with_pollinations(text, glossary):\n#     \"\"\"\n#     Translate text using Pollinations.AI API with OpenAI model\n#     \"\"\"\n#     url = \"https://text.pollinations.ai/\"\n#     prompt = f\"\"\"Translate the following Chinese web novel chapter to English. Maintain the original tone and style of the novel. Preserve any cultural references or idioms, providing brief explanations in parentheses if necessary. Ensure the translation flows naturally in English while staying true to the original text.\n    \n# Glossary for consistent translations:\n# {glossary}\n\n# Chinese text:\n# {text}\n\n# Note: Provide only the direct translation, no introduction or conclusion.\"\"\"\n\n#     payload = {\n#         \"messages\": [\n#             {\"role\": \"system\", \"content\": \"You are a professional translator specializing in Chinese to English translations.\"},\n#             {\"role\": \"user\", \"content\": prompt}\n#         ],\n#         \"model\": \"openai\",\n#         \"seed\": 42\n#     }\n    \n#     try:\n#         response = requests.post(url, json=payload, timeout=30)\n#         response.raise_for_status()\n#         translated_text = response.content.decode('utf-8')\n#         return translated_text\n#     except requests.exceptions.RequestException as e:\n#         print(f\"Pollinations API error: {str(e)}\")\n#         return None\n\n\n# def translate_task(start_chapter=1, end_chapter=None):\n#     \"\"\"\n#     Translate Chinese chapters to English using multiple APIs with fallback:\n#     1. Pollinations.AI (OpenAI)\n#     2. Google Gemini\n#     3. Groq (LLaMA)\n    \n#     Long chapters (>5000 chars) are automatically split into parts.\n#     \"\"\"\n#     # Load data and configuration\n#     with open(CHAPTERS_FILE, 'r', encoding='utf-8') as f:\n#         book_data = json.load(f)\n#     with open(GLOSSARY_FILE, 'r', encoding='utf-8') as f:\n#         glossary = json.load(f)\n#     formatted_glossary = \"\\n\".join(glossary)\n    \n#     # Configure APIs\n#     groq_api_keys = [api_key4]\n#     current_key_index = 0\n#     translations = []\n    \n#     # Configure Gemini\n#     genai.configure(api_key=user_secrets.get_secret(\"google_api_key\"))\n#     gemini_model = genai.GenerativeModel(\n#         model_name=\"gemini-1.5-flash\",\n#         generation_config={\n#             \"temperature\": 1,\n#             \"top_p\": 0.95,\n#             \"top_k\": 64,\n#             \"max_output_tokens\": 8192,\n#         }\n#     )\n\n#     # Select chapters to translate\n#     if end_chapter is not None:\n#         chapters_to_translate = book_data[start_chapter-1:end_chapter]\n#     else:\n#         chapters_to_translate = book_data\n    \n#     for i, chapter in enumerate(chapters_to_translate):\n#         if i % 10 == 0 and i != 0:\n#             current_key_index = (current_key_index + 1) % len(groq_api_keys)\n        \n#         # Split chapter if it's too long\n#         # chapter_parts = split_long_chapter(chapter['content'])\n#         # chapter_translations = []\n        \n#             # Build the translation prompt\n#         prompt = f\"\"\"Translate the following Chinese web novel chapter to English. Maintain the original tone and style of the novel. Preserve any cultural references or idioms, providing brief explanations in parentheses if necessary. Ensure the translation flows naturally in English while staying true to the original text.\n# If Paragraphs are stuck together, split them. Retain people's names in Pinyin format (e.g., Chen Jingle), but fully translate all other terms, phrases, and concepts into English. Avoid using Pinyin for non-name elements to ensure clarity and natural flow for English readers.\n\n# Glossary:\n# {formatted_glossary}\n\n# Chinese chapter:\n# {part_text}\n# Note: No introductory sentences nor concluding sentences. Just directly provide the translation.\n# Translate the above text to English, using the glossary for consistent translations of key terms:\"\"\"\n\n#         translation = None\n        \n#         # 1. Try Pollinations.AI (OpenAI) first\n#         print(f\"Attempting translation with Pollinations.AI... (Chapter {start_chapter + i}{part_suffix})\")\n#         for attempt in range(2):\n#             translation = translate_with_pollinations(part_text, formatted_glossary)\n#             if translation:\n#                 break\n#             print(f\"Pollinations.AI attempt {attempt + 1} failed. Waiting before retry...\")\n#             time.sleep(60)\n        \n#         # 2. If Pollinations failed, try Gemini\n#         if not translation:\n#             print(\"Falling back to Gemini...\")\n#             for attempt in range(2):\n#                 try:\n#                     gemini_response = gemini_model.generate_content(prompt)\n#                     translation = gemini_response.text\n#                     break\n#                 except Exception as e:\n#                     print(f\"Gemini error (attempt {attempt + 1}): {str(e)}\")\n#                     if attempt == 1:\n#                         print(\"Gemini failed. Falling back to Groq LLaMA model\")\n#                     else:\n#                         time.sleep(60)\n        \n#         # 3. If both Pollinations and Gemini failed, try Groq\n#         if not translation:\n#             current_api_key = groq_api_keys[current_key_index]\n#             client = Groq(api_key=current_api_key)\n#             for attempt in range(2):\n#                 try:\n#                     chat_completion = client.chat.completions.create(\n#                         messages=[{\"role\": \"user\", \"content\": prompt}],\n#                         model=\"llama3-70b-8192\",\n#                         timeout=30\n#                     )\n#                     translation = chat_completion.choices[0].message.content\n#                     break\n#                 except Exception as e:\n#                     print(f\"Groq error (attempt {attempt + 1}): {str(e)}\")\n#                     if attempt == 1:\n#                         print(f\"Failed to translate Chapter {start_chapter + i}{part_suffix} after all attempts\")\n#                         translation = f\"TRANSLATION FAILED: {chapter['title']}{part_suffix}\"\n#                     else:\n#                         time.sleep(60)\n        \n#         chapter_translations.append(translation)\n#         print(f\"Completed translation of Chapter {start_chapter + i}{part_suffix}\")\n#         print(\"First 500 characters of translation:\")\n#         print(translation[:500] + \"...\")\n#         print('=======================================')\n#         time.sleep(5)  # Sleep between requests\n        \n#         # Combine all parts of the chapter\n#         # full_translation = '\\n\\n'.join(chapter_translations)\n        \n#         # Add the complete chapter translation to results\n#         translations.append({\n#             'title': chapter['title'],\n#             'translated_content': full_translation\n#         })\n    \n#     # Save all translations\n#     with open(TRANSLATIONS_FILE, 'w', encoding='utf-8') as f:\n#         json.dump(translations, f, ensure_ascii=False, indent=2)\n#     print(f'Translation completed. Translations saved to {TRANSLATIONS_FILE}')\n\n# # Usage example:\n# # translate_task(start_chapter=1, end_chapter=100)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport time\nimport requests\nfrom groq import Groq\nimport google.generativeai as genai\n\n\ndef translate_with_pollinations(model='openai',text=\"\", glossary=\"\"):\n    \"\"\"\n    Translate text using Pollinations.AI API with OpenAI model\n    \"\"\"\n    url = \"https://text.pollinations.ai/\"\n    prompt = f\"\"\"Translate the following Chinese web novel chapter to English. Maintain the original tone and style of the novel. Preserve any cultural references or idioms, providing brief explanations in parentheses if necessary. Ensure the translation flows naturally in English while staying true to the original text.\n    \nGlossary for consistent translations:\n{glossary}\n\nChinese text:\n{text}\n\nNote: Provide only the direct translation, no introduction or conclusion.\"\"\"\n\n    payload = {\n        \"messages\": [\n            {\"role\": \"system\", \"content\": \"You are a professional translator specializing in Chinese to English translations.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        \"model\": model,\n        \"seed\": 42\n    }\n    \n    try:\n        response = requests.post(url, json=payload, timeout=30)\n        response.raise_for_status()\n        translated_text = response.content.decode('utf-8')\n        return translated_text\n    except requests.exceptions.RequestException as e:\n        print(f\"Pollinations API error: {str(e)}\")\n        return None\n\ndef translate_task(start_chapter=1, end_chapter=None):\n    \"\"\"\n    Translate Chinese chapters to English using multiple APIs with fallback:\n    1. Pollinations.AI (OpenAI)\n    2. Google Gemini\n    3. Groq (LLaMA)\n    \"\"\"\n    # Load data and configuration\n    with open(SPLIT_CHAPTERS_FILE, 'r', encoding='utf-8') as f:\n        book_data = json.load(f)\n    with open(GLOSSARY_FILE, 'r', encoding='utf-8') as f:\n        glossary = json.load(f)\n    formatted_glossary = \"\\n\".join(glossary)\n    \n    # Configure APIs\n    groq_api_keys = [api_key4]\n    current_key_index = 0\n    translations = []\n    \n    # Configure Gemini\n    genai.configure(api_key='AIzaSyDuh1xQkSUHsov78ldbO9dVWmlD3-LfjlU')\n    gemini_model = genai.GenerativeModel(\n        model_name=\"gemini-1.5-flash\",\n        generation_config={\n            \"temperature\": 1,\n            \"top_p\": 0.95,\n            \"top_k\": 64,\n            \"max_output_tokens\": 8192,\n        }\n    )\n\n    # Select chapters to translate\n    if end_chapter is not None:\n        chapters_to_translate = book_data[start_chapter-1:end_chapter]\n    else:\n        chapters_to_translate = book_data\n    \n    for i, chapter in enumerate(chapters_to_translate):\n        if i % 10 == 0 and i != 0:\n            current_key_index = (current_key_index + 1) % len(groq_api_keys)\n        \n        # Build the translation prompt\n        prompt = f\"\"\"Translate the following Chinese web novel chapter to English. Maintain the original tone and style of the novel. Preserve any cultural references or idioms, providing brief explanations in parentheses if necessary. \nIf Paragraphs are stuck together, split them. Retain people's names in Pinyin format (e.g., Chen Jingle), but fully translate all other terms, phrases, and concepts into English. Avoid using Pinyin for non-name elements to ensure clarity and natural flow for English readers.\nYou should translate every chinese character to English. The chapter should be fully translated.\nGlossary:\n{formatted_glossary}\n\nChinese chapter:\n{chapter['content']}\nNote: No introductory sentences nor concluding sentences. Just directly provide the translation.\nTranslate the above text to English, using the glossary for consistent translations of key terms:\"\"\"\n\n        translation = None\n        \n        # 1. Try Pollinations.AI (OpenAI) first\n        # print(f\"Attempting translation with Pollinations.AI... (Chapter {start_chapter + i})\")\n        # for attempt in range(2):\n        #     translation = translate_with_pollinations('openai',chapter['content'], formatted_glossary)\n        #     if translation:\n        #         break\n        #     print(f\"Pollinations.AI attempt with llama {attempt + 1} failed. Waiting before retry...\")\n        #     time.sleep(30)\n        # if not translation:\n        #     print(f\"Attempting translation with Pollinations.AI... (Chapter {start_chapter + i})\")\n        #     for attempt in range(2):\n        #         translation = translate_with_pollinations('deepseek',chapter['content'], formatted_glossary)\n        #         if translation:\n        #             break\n        #         print(f\"Pollinations.AI attempt with deepseek {attempt + 1} failed. Waiting before retry...\")\n        #         time.sleep(30)\n        \n        \n        # # 2. If Pollinations failed, try Gemini\n        # if not translation:\n        print(\"Falling back to Gemini...\")\n        for attempt in range(2):\n            try:\n                gemini_response = gemini_model.generate_content(prompt)\n                translation = gemini_response.text\n                break\n            except Exception as e:\n                print(f\"Gemini error (attempt {attempt + 1}): {str(e)}\")\n                if attempt == 1:\n                    print(\"Gemini failed. Falling back to Groq LLaMA model\")\n                else:\n                    time.sleep(30)\n        \n        # 3. If both Pollinations and Gemini failed, try Groq\n        if not translation:\n            current_api_key = groq_api_keys[current_key_index]\n            client = Groq(api_key=current_api_key)\n            for attempt in range(2):\n                try:\n                    chat_completion = client.chat.completions.create(\n                        messages=[{\"role\": \"user\", \"content\": prompt}],\n                        model=\"llama3-70b-8192\",\n                        timeout=30\n                    )\n                    translation = chat_completion.choices[0].message.content\n                    break\n                except Exception as e:\n                    print(f\"Groq error (attempt {attempt + 1}): {str(e)}\")\n                    if attempt == 1:\n                        print(f\"Failed to translate Chapter {start_chapter + i} after all attempts\")\n                        translation = f\"TRANSLATION FAILED: {chapter['title']}\"\n                    else:\n                        time.sleep(30)\n        \n        # Add the complete chapter translation to results\n        translations.append({\n            'title': chapter['title'],\n            'translated_content': translation\n        })\n        print(f\"Completed translation of Chapter {start_chapter + i}\")\n        print(\"First 500 characters of translation:\")\n        print(translation[:500]+ \"...\")\n        print('=======================================')\n        time.sleep(5)  # Sleep between requests\n    \n    # Save all translations\n    with open(TRANSLATIONS_FILE, 'w', encoding='utf-8') as f:\n        json.dump(translations, f, ensure_ascii=False, indent=2)\n    print(f'Translation completed. Translations saved to {TRANSLATIONS_FILE}')\n\n# Usage example:\n# translate_task(start_chapter=1, end_chapter=100)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T09:47:17.851857Z","iopub.execute_input":"2025-01-21T09:47:17.852341Z","iopub.status.idle":"2025-01-21T09:47:19.526506Z","shell.execute_reply.started":"2025-01-21T09:47:17.852293Z","shell.execute_reply":"2025-01-21T09:47:19.525395Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import json\n# import time\n# import requests\n# from groq import Groq\n# import google.generativeai as genai\n\n\n# def translate_with_pollinations(model='openai',text=\"\", glossary=\"\"):\n#     \"\"\"\n#     Translate text using Pollinations.AI API with OpenAI model\n#     \"\"\"\n#     url = \"https://text.pollinations.ai/\"\n#     prompt = f\"\"\"Translate the following Chinese web novel chapter to English. Maintain the original tone and style of the novel. Preserve any cultural references or idioms, providing brief explanations in parentheses if necessary. Ensure the translation flows naturally in English while staying true to the original text.\n    \n# Glossary for consistent translations:\n# {glossary}\n\n# Chinese text:\n# {text}\n\n# Note: Provide only the direct translation, no introduction or conclusion.\"\"\"\n\n#     payload = {\n#         \"messages\": [\n#             {\"role\": \"system\", \"content\": \"You are a professional translator specializing in Chinese to English translations.\"},\n#             {\"role\": \"user\", \"content\": prompt}\n#         ],\n#         \"model\": model,\n#         \"seed\": 42\n#     }\n    \n#     try:\n#         response = requests.post(url, json=payload, timeout=30)\n#         response.raise_for_status()\n#         translated_text = response.content.decode('utf-8')\n#         return translated_text\n#     except requests.exceptions.RequestException as e:\n#         print(f\"Pollinations API error: {str(e)}\")\n#         return None\n\n# def translate_task(start_chapter=1, end_chapter=None):\n#     \"\"\"\n#     Translate Chinese chapters to English using multiple APIs with fallback:\n#     1. Pollinations.AI (OpenAI)\n#     2. Google Gemini\n#     3. Groq (LLaMA)\n#     \"\"\"\n#     # Load data and configuration\n#     with open(SPLIT_CHAPTERS_FILE, 'r', encoding='utf-8') as f:\n#         book_data = json.load(f)\n#     with open(GLOSSARY_FILE, 'r', encoding='utf-8') as f:\n#         glossary = json.load(f)\n#     formatted_glossary = \"\\n\".join(glossary)\n    \n#     # Configure APIs\n#     groq_api_keys = [api_key4]\n#     current_key_index = 0\n#     translations = []\n    \n#     # Configure Gemini\n#     genai.configure(api_key='AIzaSyDuh1xQkSUHsov78ldbO9dVWmlD3-LfjlU')\n#     gemini_model = genai.GenerativeModel(\n#         model_name=\"gemini-1.5-flash\",\n#         generation_config={\n#             \"temperature\": 1,\n#             \"top_p\": 0.95,\n#             \"top_k\": 64,\n#             \"max_output_tokens\": 8192,\n#         }\n#     )\n\n#     # Select chapters to translate\n#     if end_chapter is not None:\n#         chapters_to_translate = book_data[start_chapter-1:end_chapter]\n#     else:\n#         chapters_to_translate = book_data\n    \n#     for i, chapter in enumerate(chapters_to_translate):\n#         if i % 10 == 0 and i != 0:\n#             current_key_index = (current_key_index + 1) % len(groq_api_keys)\n        \n#         # Build the translation prompt\n#         prompt = f\"\"\"Translate the following Chinese web novel chapter to English. Maintain the original tone and style of the novel. Preserve any cultural references or idioms, providing brief explanations in parentheses if necessary. Ensure the translation flows naturally in English while staying true to the original text.\n# If Paragraphs are stuck together, split them. Retain people's names in Pinyin format (e.g., Chen Jingle), but fully translate all other terms, phrases, and concepts into English. Avoid using Pinyin for non-name elements to ensure clarity and natural flow for English readers.\n\n# Glossary:\n# {formatted_glossary}\n\n# Chinese chapter:\n# {chapter['content']}\n# Note: No introductory sentences nor concluding sentences. Just directly provide the translation.\n# Translate the above text to English, using the glossary for consistent translations of key terms:\"\"\"\n\n#         translation = None\n        \n#         # 1. Try Pollinations.AI (OpenAI) first\n#         print(f\"Attempting translation with Pollinations.AI... (Chapter {start_chapter + i})\")\n#         for attempt in range(2):\n#             translation = translate_with_pollinations('openai',chapter['content'], formatted_glossary)\n#             if translation:\n#                 break\n#             print(f\"Pollinations.AI attempt with llama {attempt + 1} failed. Waiting before retry...\")\n#             time.sleep(30)\n#         if not translation:\n#             print(f\"Attempting translation with Pollinations.AI... (Chapter {start_chapter + i})\")\n#             for attempt in range(2):\n#                 translation = translate_with_pollinations('deepseek',chapter['content'], formatted_glossary)\n#                 if translation:\n#                     break\n#                 print(f\"Pollinations.AI attempt with deepseek {attempt + 1} failed. Waiting before retry...\")\n#                 time.sleep(30)\n        \n        \n#         # 2. If Pollinations failed, try Gemini\n#         if not translation:\n#             print(\"Falling back to Gemini...\")\n#             for attempt in range(2):\n#                 try:\n#                     gemini_response = gemini_model.generate_content(prompt)\n#                     translation = gemini_response.text\n#                     break\n#                 except Exception as e:\n#                     print(f\"Gemini error (attempt {attempt + 1}): {str(e)}\")\n#                     if attempt == 1:\n#                         print(\"Gemini failed. Falling back to Groq LLaMA model\")\n#                     else:\n#                         time.sleep(30)\n        \n#         # 3. If both Pollinations and Gemini failed, try Groq\n#         if not translation:\n#             current_api_key = groq_api_keys[current_key_index]\n#             client = Groq(api_key=current_api_key)\n#             for attempt in range(2):\n#                 try:\n#                     chat_completion = client.chat.completions.create(\n#                         messages=[{\"role\": \"user\", \"content\": prompt}],\n#                         model=\"llama3-70b-8192\",\n#                         timeout=30\n#                     )\n#                     translation = chat_completion.choices[0].message.content\n#                     break\n#                 except Exception as e:\n#                     print(f\"Groq error (attempt {attempt + 1}): {str(e)}\")\n#                     if attempt == 1:\n#                         print(f\"Failed to translate Chapter {start_chapter + i} after all attempts\")\n#                         translation = f\"TRANSLATION FAILED: {chapter['title']}\"\n#                     else:\n#                         time.sleep(30)\n        \n#         # Add the complete chapter translation to results\n#         translations.append({\n#             'title': chapter['title'],\n#             'translated_content': translation\n#         })\n#         print(f\"Completed translation of Chapter {start_chapter + i}\")\n#         print(\"First 500 characters of translation:\")\n#         print(translation[:500]+ \"...\")\n#         print('=======================================')\n#         time.sleep(5)  # Sleep between requests\n    \n#     # Save all translations\n#     with open(TRANSLATIONS_FILE, 'w', encoding='utf-8') as f:\n#         json.dump(translations, f, ensure_ascii=False, indent=2)\n#     print(f'Translation completed. Translations saved to {TRANSLATIONS_FILE}')\n\n# # Usage example:\n# # translate_task(start_chapter=1, end_chapter=100)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Usage\ntranslate_task(start_chapter=start_chapter_number,end_chapter=end_chapter_number)  # This will translate chapters 1 to 100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T09:48:08.413018Z","iopub.execute_input":"2025-01-21T09:48:08.413615Z","iopub.status.idle":"2025-01-21T09:48:38.17544Z","shell.execute_reply.started":"2025-01-21T09:48:08.413575Z","shell.execute_reply":"2025-01-21T09:48:38.173952Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import requests\nimport json\nfrom datetime import datetime, timedelta\nimport pytz\nfrom requests.auth import HTTPBasicAuth\n\nAPI_URL = 'https://untoldchapters.com/wp-json/wp/v2'\nCategory_API_URL = 'https://untoldchapters.com/wp-json/wp/v2/categories'\nUSERNAME = 'admin'\nPASSWORD = 'VZ4y n8go 1Ep6 luIU fSfA DFLu'\nTOC_URL = f'https://untoldchapters.com/{novel_slug}'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T02:35:09.045161Z","iopub.execute_input":"2025-01-12T02:35:09.04558Z","iopub.status.idle":"2025-01-12T02:35:09.131629Z","shell.execute_reply.started":"2025-01-12T02:35:09.045546Z","shell.execute_reply":"2025-01-12T02:35:09.130268Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import requests\n\n# def create_wordpress_post(api_url, username, password, title, content, status=\"publish\", date=None):\n#     post_data = {\n#         \"title\": title,\n#         \"content\": content,\n#         \"status\": status\n#     }\n#     if date:\n#         post_data[\"date\"] = date  # Add the date field if provided\n    \n#     response = requests.post(\n#         api_url,\n#         auth=(username, password),\n#         json=post_data\n#     )\n    \n#     # Check if the request was successful\n#     if response.status_code == 201:\n#         print(\"Post created successfully:\", response.json()[\"link\"])\n#     else:\n#         print(\"Failed to create post:\", response.status_code, response.json())\n    \n#     return response.json()\n\n# # Example Usage:\n# title = \"Test Post2\"\n# content = \"This is the content of the test post.\"\n# status = \"future\"\n# date = \"2024-12-22T10:00:00\"  # Optional: for scheduling posts\n# api_url = 'https://untoldchapters.com/wp-json/wp/v2/posts'\n# create_wordpress_post(api_url, USERNAME, PASSWORD, title, content, status, date)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-09T07:49:36.589Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import requests\nimport json\nfrom datetime import datetime, timedelta\nimport pytz\n# Payload for creating the category\ndata = {\n    \"name\": novel_title,\n    \"slug\": novel_slug,\n    \"description\": \"\"\n}\n\n# Make the POST request to create the category\nresponse = requests.post(Category_API_URL, \n                         data=json.dumps(data), \n                         headers={'Content-Type': 'application/json'},\n                         auth=HTTPBasicAuth(USERNAME, PASSWORD))\n\n# Check the response\nif response.status_code == 201:\n    print(\"Category created successfully:\", response.json())\nelse:\n    print(\"Failed to create category. Status Code:\", response.status_code)\n    print(\"Response:\", response.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T02:37:51.352004Z","iopub.execute_input":"2025-01-12T02:37:51.35242Z","iopub.status.idle":"2025-01-12T02:37:52.063142Z","shell.execute_reply.started":"2025-01-12T02:37:51.352386Z","shell.execute_reply":"2025-01-12T02:37:52.061815Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"category_id = response.json()['id']\n# category_id = 81","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T02:37:55.755602Z","iopub.execute_input":"2025-01-12T02:37:55.756007Z","iopub.status.idle":"2025-01-12T02:37:55.762777Z","shell.execute_reply.started":"2025-01-12T02:37:55.755959Z","shell.execute_reply":"2025-01-12T02:37:55.761062Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_post(title, content, slug, username, password, scheduled_date, category_id):\n   post_data = {\n       'title': title,\n       'content': content,\n       'status': 'future',\n       'date': scheduled_date.isoformat(),\n       'slug': slug,\n       'categories': [category_id],\n       'meta': {\n           'rank_math_focus_keyword': title.replace(',', '')\n       }\n   }\n   response = requests.post(\n       f'{API_URL}/posts',\n       auth=(username, password),\n       json=post_data\n   )\n   return response.json()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T02:38:01.285475Z","iopub.execute_input":"2025-01-12T02:38:01.285921Z","iopub.status.idle":"2025-01-12T02:38:01.293781Z","shell.execute_reply.started":"2025-01-12T02:38:01.285885Z","shell.execute_reply":"2025-01-12T02:38:01.292216Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## release first ten chapters then one by one daily","metadata":{}},{"cell_type":"code","source":"def process_chapters(chapters_file, username, password, novel_title, novel_slug, chapter_start, category_id):\n    with open(chapters_file, 'r') as file:\n        chapters = json.load(file)\n\n    # Get current time in GMT+5:45\n    nepal_tz = pytz.timezone('Asia/Kathmandu')\n    current_time = datetime.now(nepal_tz)\n    \n    # Set initial post time\n    next_post_time = current_time\n    \n    for i, chapter in enumerate(chapters, chapter_start):\n        title = f\"{novel_title} {i}\"\n        slug = f\"{novel_slug}-{i}\"\n        \n        # Remove specified words/phrases from content\n        content = chapter['translated_content']\n        # for word in remove_words:\n        #     content = content.replace(word, '')\n        \n        # Create navigation links\n        prev_link = f'<a href=\"https://untoldchapters.com/{novel_slug}-{i-1}/\">Previous Chapter</a>' if i > 1 else ''\n        next_link = f'<a href=\"https://untoldchapters.com/{novel_slug}-{i+1}/\">Next Chapter</a>' if i < len(chapters) else ''\n        toc_link = f'<a href=\"{TOC_URL}\">TOC</a>'\n        \n        navigation = f'<p>{prev_link} | {toc_link} | {next_link}</p>'\n        content = f\"{content}\\n\\n{navigation}\"\n        \n        # Schedule posts\n        if i <= 10:\n            # First ten chapters: 3-hour interval\n            scheduled_time = next_post_time\n            next_post_time += timedelta(hours=1)\n        else:\n            # Subsequent chapters: one per day\n            scheduled_time = next_post_time\n            next_post_time += timedelta(hours=8)\n        \n        # Create and schedule the post\n        create_post(title, content, slug, username, password, scheduled_time, category_id)\n        print(f\"Scheduled post for {title} at {scheduled_time}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T02:40:05.907824Z","iopub.execute_input":"2025-01-12T02:40:05.908288Z","iopub.status.idle":"2025-01-12T02:40:05.919733Z","shell.execute_reply.started":"2025-01-12T02:40:05.908253Z","shell.execute_reply":"2025-01-12T02:40:05.918106Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chapters_file=TRANSLATIONS_FILE\nprocess_chapters(chapters_file, USERNAME, PASSWORD, novel_title, novel_slug, chapter_start, category_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T02:40:11.538897Z","iopub.execute_input":"2025-01-12T02:40:11.539296Z","iopub.status.idle":"2025-01-12T02:46:01.215402Z","shell.execute_reply.started":"2025-01-12T02:40:11.539263Z","shell.execute_reply":"2025-01-12T02:46:01.213671Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4 chapters","metadata":{}},{"cell_type":"code","source":"# import requests\n# import json\n# from datetime import datetime, timedelta\n# import pytz\n\n# # List of words/phrases to remove from the content\n# remove_words = [\n#     \"Notice to Android users, more and more free sites will be closed and will fail, Android app is flooded with fishy links, finding a secure and stable app for reading is very necessary, the editor strongly recommends switching to a new app, listening, switching, and finding books is super easy!\",\n#     \"Reader ID: 伍陸彡⑦④彡陸⑦伍\",\n#     \"Discussion group: 五六③⑦四三陆七伍\",\n#     \"【Notification to Android book friends...】\",\n#     \"Password 伍陸彡⑦④彡陸⑦伍\",\n#     \"Notification to Book Friends: The era is changing, and free websites are hard to maintain. Mobile apps are switching to multiple sources, and the trend is to read books on the recommended app, which has rich audio, source switching, and search functions!\",\n#     \"Tower Read\",\n#     \"Tower Read says: No ads, no pop-ups, just pure reading experience!\"\n# ]\n\n# def create_post(title, content, slug, username, password, scheduled_date, category_id):\n#     post_data = {\n#         'title': title,\n#         'content': content,\n#         'status': 'future',\n#         'date': scheduled_date.isoformat(),\n#         'slug': slug,\n#         'categories': [category_id],\n#         'meta': {\n#             'rank_math_focus_keyword': title.replace(',', '')\n#         }\n#     }\n#     response = requests.post(\n#         f'{API_URL}/posts',\n#         auth=(username, password),\n#         json=post_data\n#     )\n#     return response.json()\n\n# def process_chapters(chapters_file, username, password, novel_title, novel_slug, chapter_start, category_id):\n#     with open(chapters_file, 'r') as file:\n#         chapters = json.load(file)\n    \n#     # Get current time in GMT+5:45\n#     nepal_tz = pytz.timezone('Asia/Kathmandu')\n#     current_time = datetime.now(nepal_tz)\n    \n#     # Set the initial post time to the next 1 AM\n#     next_post_time = current_time.replace(hour=1, minute=0, second=0, microsecond=0)\n#     if current_time.time() >= next_post_time.time():\n#         next_post_time += timedelta(days=1)\n    \n#     # Define posting intervals (1 AM, 7 AM, 1 PM, and 7 PM)\n#     post_intervals = [0, 6, 12, 18]\n#     # post_intervals=[6,18]wrong\n    \n#     for i, chapter in enumerate(chapters, chapter_start):\n#         title = f\"{novel_title} {i}\"\n#         slug = f\"{novel_slug}-{i}\"\n        \n#         # Remove specified words/phrases from content\n#         content = chapter['translated_content']\n#         for word in remove_words:\n#             content = content.replace(word, '')\n            \n#         # Create navigation links\n#         prev_link = f'<a href=\"https://untoldchapters.com/{novel_slug}-{i-1}/\">Previous Chapter</a>' if i > 1 else ''\n#         next_link = f'<a href=\"https://untoldchapters.com/{novel_slug}-{i+1}/\">Next Chapter</a>' if i < len(chapters) else ''\n#         toc_link = f'<a href=\"{TOC_URL}\">TOC</a>'\n        \n#         navigation = f'<p>{prev_link} | {toc_link} | {next_link}</p>'\n#         content = f\"{content}\\n\\n{navigation}\"\n        \n#         # Schedule the chapter every 6 hours\n#         scheduled_time = next_post_time + timedelta(hours=post_intervals[i % 4])\n        \n#         # Create and schedule the post\n#         create_post(title, content, slug, username, password, scheduled_time, category_id)\n#         print(f\"Scheduled post for {title} at {scheduled_time}\")\n        \n#         # After scheduling four posts, advance to the next day\n#         if (i + 1) % 4 == 0:\n#             next_post_time += timedelta(days=1)\n\n# # Usage\n# chapters_file = TRANSLATIONS_FILE\n# process_chapters(chapters_file, USERNAME, PASSWORD, novel_title, novel_slug, chapter_start, category_id)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-09T07:49:36.589Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2 chapters","metadata":{}},{"cell_type":"code","source":"# import requests\n# import json\n# from datetime import datetime, timedelta\n# import pytz\n\n# # Configure posting times (24-hour format)\n# MORNING_POST_HOUR = 4  # 3 AM\n# AFTERNOON_POST_HOUR = 16  # 3 PM (15:00)\n\n# # List of words/phrases to remove from the content\n# remove_words = [\"Notice to Android users, more and more free sites will be closed and will fail, Android app is flooded with fishy links, finding a secure and stable app for reading is very necessary, the editor strongly recommends switching to a new app, listening, switching, and finding books is super easy!\",\n#                \"Reader ID: 伍陸彡⑦④彡陸⑦伍\",\n#                \"Discussion group: 五六③⑦四三陆七伍\",\n#                \"【Notification to Android book friends...】\",\n#                \"Password 伍陸彡⑦④彡陸⑦伍\",\n#               \"Notification to Book Friends: The era is changing, and free websites are hard to maintain. Mobile apps are switching to multiple sources, and the trend is to read books on the recommended app, which has rich audio, source switching, and search functions!\",\n#               \"Tower Read\",\n#                \"Tower Read says: No ads, no pop-ups, just pure reading experience!\"\n#               ]\n\n\n# def process_chapters(chapters_file, username, password, novel_title, novel_slug, chapter_start, category_id):\n#    with open(chapters_file, 'r') as file:\n#        chapters = json.load(file)\n   \n#    # Get current time in GMT+5:45\n#    nepal_tz = pytz.timezone('Asia/Kathmandu')\n#    current_time = datetime.now(nepal_tz)\n   \n#    # Set the first chapter time to next MORNING_POST_HOUR\n#    next_post_time = current_time.replace(hour=MORNING_POST_HOUR, minute=0, second=0, microsecond=0)\n#    if current_time.time() >= next_post_time.time():\n#        next_post_time += timedelta(days=1)\n   \n#    # Set the second chapter time to AFTERNOON_POST_HOUR\n#    second_post_time = next_post_time.replace(hour=AFTERNOON_POST_HOUR)\n   \n#    for i, chapter in enumerate(chapters, chapter_start):\n#        title = f\"{novel_title} {i}\"\n#        slug = f\"{novel_slug}-{i}\"\n       \n#        # Remove specified words/phrases from content\n#        content = chapter['translated_content']\n#        for word in remove_words:\n#            content = content.replace(word, '')\n           \n#        # Create navigation links\n#        prev_link = f'<a href=\"https://untoldchapters.com/{novel_slug}-{i-1}/\">Previous Chapter</a>' if i > 1 else ''\n#        next_link = f'<a href=\"https://untoldchapters.com/{novel_slug}-{i+1}/\">Next Chapter</a>' if i < len(chapters) else ''\n#        toc_link = f'<a href=\"{TOC_URL}\">TOC</a>'\n       \n#        navigation = f'<p>{prev_link} | {toc_link} | {next_link}</p>'\n#        content = f\"{content}\\n\\n{navigation}\"\n       \n#        # Alternate between morning and afternoon scheduling\n#        scheduled_time = next_post_time if i % 2 == 0 else second_post_time\n       \n#        # Create and schedule the post\n#        create_post(title, content, slug, username, password, scheduled_time, category_id)\n#        print(f\"Scheduled post for {title} at {scheduled_time}\")\n       \n#        # If we've scheduled both posts for the day, move to next day\n#        if i % 2 == 1:\n#            next_post_time += timedelta(days=1)\n#            second_post_time += timedelta(days=1)\n\n# # Usage\n# chapters_file = TRANSLATIONS_FILE\n# process_chapters(chapters_file, USERNAME, PASSWORD, novel_title, novel_slug, chapter_start, category_id)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-09T07:49:36.589Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import requests\n# import json\n# from datetime import datetime, timedelta\n# import pytz\n\n\n\n# # List of words/phrases to remove from the content\n# remove_words = [\"Notice to Android users, more and more free sites will be closed and will fail, Android app is flooded with fishy links, finding a secure and stable app for reading is very necessary, the editor strongly recommends switching to a new app, listening, switching, and finding books is super easy!\",\n#                 \"Reader ID: 伍陸彡⑦④彡陸⑦伍\",\n#                 \"Discussion group: 五六③⑦四三陆七伍\",\n#                 \"【Notification to Android book friends...】\",\n#                 \"Password 伍陸彡⑦④彡陸⑦伍\",\n#                \"Notification to Book Friends: The era is changing, and free websites are hard to maintain. Mobile apps are switching to multiple sources, and the trend is to read books on the recommended app, which has rich audio, source switching, and search functions!\",\n#                \"Tower Read\",\n#                 \"Tower Read says: No ads, no pop-ups, just pure reading experience!\"\n#                ]\n\n# def create_post(title, content, slug, username, password, scheduled_date, category_id):\n    \n#     post_data = {\n#         'title': title,\n#         'content': content,\n#         'status': 'future',\n#         'date': scheduled_date.isoformat(),\n#         'slug': slug,\n#         'categories': [category_id],\n#         'meta': {\n#             'rank_math_focus_keyword': title.replace(',', '')\n#         }\n#     }\n#     response = requests.post(\n#         f'{API_URL}/posts',\n#         auth=(username, password),\n#         json=post_data\n#     )\n#     return response.json()\n\n# def process_chapters(chapters_file, username, password, novel_title, novel_slug, chapter_start, category_id):\n#     with open(chapters_file, 'r') as file:\n#         chapters = json.load(file)\n    \n#     # Get current time in GMT+5:45\n#     nepal_tz = pytz.timezone('Asia/Kathmandu')\n#     current_time = datetime.now(nepal_tz)\n    \n#     # Set the first chapter time to next 1 AM\n#     next_post_time = current_time.replace(hour=1, minute=0, second=0, microsecond=0)\n#     if current_time.time() >= next_post_time.time():\n#         next_post_time += timedelta(days=1)\n    \n#     # Set the second chapter time to 1 PM (13:00)\n#     second_post_time = next_post_time.replace(hour=13)\n    \n#     for i, chapter in enumerate(chapters, chapter_start):\n#         title = f\"{novel_title} {i}\"\n#         slug = f\"{novel_slug}-{i}\"\n        \n#         # Remove specified words/phrases from content\n#         content = chapter['translated_content']\n#         for word in remove_words:\n#             content = content.replace(word, '')\n            \n#         # Create navigation links\n#         prev_link = f'<a href=\"https://untoldchapters.com/{novel_slug}-{i-1}/\">Previous Chapter</a>' if i > 1 else ''\n#         next_link = f'<a href=\"https://untoldchapters.com/{novel_slug}-{i+1}/\">Next Chapter</a>' if i < len(chapters) else ''\n#         toc_link = f'<a href=\"{TOC_URL}\">TOC</a>'\n        \n#         navigation = f'<p>{prev_link} | {toc_link} | {next_link}</p>'\n#         content = f\"{content}\\n\\n{navigation}\"\n        \n#         # Alternate between 1 AM and 1 PM scheduling\n#         scheduled_time = next_post_time if i % 2 == 0 else second_post_time\n        \n#         # Create and schedule the post\n#         create_post(title, content, slug, username, password, scheduled_time, category_id)\n#         print(f\"Scheduled post for {title} at {scheduled_time}\")\n        \n#         # If we've scheduled both posts for the day, move to next day\n#         if i % 2 == 1:\n#             next_post_time += timedelta(days=1)\n#             second_post_time += timedelta(days=1)\n\n# # Usage\n# chapters_file = TRANSLATIONS_FILE\n# # chapters_file = '/kaggle/input/exclusive-sweetheart/exclusive sweetheart web novel.json'\n# process_chapters(chapters_file, USERNAME, PASSWORD, novel_title, novel_slug, chapter_start, category_id)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-09T07:49:36.589Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def test_post_creation():\n#     current_time = datetime.now(pytz.UTC)\n#     schedule_time = current_time + timedelta(hours=1)\n#     formatted_date = schedule_time.isoformat().replace('+00:00', 'Z')\n    \n#     # post_data = {\n#     #     'title': 'Test Post - Please Ignore',\n#     #     'content': 'This is a test post to verify scheduling functionality.',\n#     #     'status': 'future',\n#     #     'date': formatted_date,\n#     #     'date_gmt': formatted_date,\n#     #     'slug': 'test-post-' + current_time.strftime('%Y%m%d-%H%M'),\n#     #     'categories': [77]\n#     # }\n#     post_data = {\n#     'title': \"Test Post 1\",\n#     'content': \"This is a test post.\",\n#     'status': 'future',\n#     'date': '2024-12-22T10:00:00',  # Local time\n#     # 'date_gmt': '2024-12-22T04:15:00',  # Corresponding UTC time\n# }\n\n#     try:\n#         response = requests.post(\n#             f'{API_URL}/posts',\n#             auth=(USERNAME, PASSWORD),\n#             json=post_data\n#         )\n        \n#         if response.status_code == 201:\n#             print(\"Success! Post scheduled.\")\n#             print(f\"Scheduled time: {formatted_date}\")\n#             print(f\"Response: {json.dumps(response.json(), indent=2)}\")\n#         else:\n#             print(f\"Error: {response.status_code}\")\n#             print(f\"Response: {response.text}\")\n            \n#     except Exception as e:\n#         print(f\"Error occurred: {str(e)}\")\n\n# test_post_creation()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-09T07:49:36.59Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}